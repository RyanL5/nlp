{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2 Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from default import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the default solution on dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sides edge bottom front club line both back place corner\n",
      "sides edge bottom front club line both back place corner\n",
      "sides edge bottom front club line both back place corner\n",
      "sides edge bottom front club line both back place corner\n",
      "sides edge bottom front club line both back place corner\n",
      "sides edge bottom front club line both back place corner\n",
      "sides edge bottom front club line both back place corner\n",
      "sides edge bottom front club line both back place corner\n",
      "sides edge bottom front club line both back place corner\n",
      "sides edge bottom front club line both back place corner\n"
     ]
    }
   ],
   "source": [
    "lexsub = LexSub(os.path.join('data','glove.6B.100d.magnitude'))\n",
    "output = []\n",
    "with open(os.path.join('data','input','dev.txt')) as f:\n",
    "    for line in f:\n",
    "        fields = line.strip().split('\\t')\n",
    "        output.append(\" \".join(lexsub.substitutes(int(fields[0].strip()), fields[1].strip().split())))\n",
    "print(\"\\n\".join(output[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the default output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=27.89\n"
     ]
    }
   ],
   "source": [
    "from lexsub_check import precision\n",
    "with open(os.path.join('data','reference','dev.out'), 'rt') as refh:\n",
    "    ref_data = [str(x).strip() for x in refh.read().splitlines()]\n",
    "print(\"Score={:.2f}\".format(100*precision(ref_data, output)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for retrofit word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_word(word):\n",
    "  if word.lower().isdigit():\n",
    "    return '-number-'\n",
    "  elif word.lower() == '':\n",
    "    return '-punctuation-'\n",
    "  else:\n",
    "    return word.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The norm_word function simply normalize a word in the lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lex(lex_file):\n",
    "    lexicon = {}\n",
    "    for line in open(lex_file, 'r'):\n",
    "        words = line.lower().strip().split()\n",
    "        lexicon[norm_word(words[0])] = [norm_word(word) for word in words[1:]]\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The read_lex function read a lexicon txt file and write it as dictionary for latter use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_wvtxt(wordVec, outFileName):\n",
    "    sys.stderr.write('\\nWriting retrofitted word vectors in '+outFileName+'\\n')\n",
    "    output = open(outFileName, 'w')  \n",
    "    for word, values in wordVec.items():\n",
    "        output.write(word+' ')\n",
    "        for element in wordVec[word]:\n",
    "            output.write('%.5f' %(element)+' ')\n",
    "        output.write('\\n')      \n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The write_wvtxt function write the retrofitted new word vector into a new txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrofit(self, lexicon, T = 10):\n",
    "        # initialize retrofit word vector equal to origin word vector\n",
    "        newwv = {}\n",
    "        for key, vector in self.wvecs:\n",
    "            newwv[key] = vector\n",
    "\n",
    "        loopVocab = []\n",
    "        for key in lexicon:\n",
    "            if key in self.wvecs:\n",
    "                loopVocab.append(key)\n",
    "\n",
    "        for i in range(T):\n",
    "            for word in loopVocab:\n",
    "\n",
    "                wordneighbours = []\n",
    "                for neighbours in lexicon[word]:\n",
    "                    if neighbours in self.wvecs:\n",
    "                        wordneighbours.append(neighbours)\n",
    "                numneighbours = len(wordneighbours)\n",
    "                # pass if no neighbours (use original dataset)\n",
    "                if numneighbours == 0:\n",
    "                    continue\n",
    "                # the weight(sum of bij and aij) of the data estimate is the number of neighbours\n",
    "                newVec= numneighbours * self.wvecs.query(word)\n",
    "\n",
    "                for qjword in wordneighbours:\n",
    "                    newVec += newwv[qjword]\n",
    "\n",
    "                newwv[word] = newVec / (2 * numneighbours)\n",
    "\n",
    "        return newwv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retrofit function will take a lexicon dictionary and T = 10(changes in Euclidean distance of adjacent vertices of roughly 10−2) as the parameter. It will first copy the original word vector and generate a retrofitted word vector. The weight of the data estimate(bij and aij in the assignment instructor)is the number of neighbors correspond to a specific word. For the words which do not have any neighbors (no edge connect it with other words), we use the original dataset without retrofit it's word vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the retrofitted solution on dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge front bottom line corner back left then way along\n",
      "edge front bottom line corner back left then way along\n",
      "edge front bottom line corner back left then way along\n",
      "edge front bottom line corner back left then way along\n",
      "edge front bottom line corner back left then way along\n",
      "edge front bottom line corner back left then way along\n",
      "edge front bottom line corner back left then way along\n",
      "edge front bottom line corner back left then way along\n",
      "edge front bottom line corner back left then way along\n",
      "edge front bottom line corner back left then way along\n"
     ]
    }
   ],
   "source": [
    "lexsub = LexSub(os.path.join('data','glove.6B.100d.retrofit.magnitude'))\n",
    "output = []\n",
    "with open(os.path.join('data','input','dev.txt')) as f:\n",
    "    for line in f:\n",
    "        fields = line.strip().split('\\t')\n",
    "        output.append(\" \".join(lexsub.substitutes(int(fields[0].strip()), fields[1].strip().split())))\n",
    "print(\"\\n\".join(output[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the retrofitted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score=40.87\n"
     ]
    }
   ],
   "source": [
    "from lexsub_check import precision\n",
    "with open(os.path.join('data','reference','dev.out'), 'rt') as refh:\n",
    "    ref_data = [str(x).strip() for x in refh.read().splitlines()]\n",
    "print(\"Score={:.2f}\".format(100*precision(ref_data, output)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substitutes2 function (Incorporating Context Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitutes2(self, index, sentence):\n",
    "        substitutability = {}\n",
    "        target = sentence[index]\n",
    "        sentential_context = sentence\n",
    "        guesses = []\n",
    "        neighbours = list(map(lambda k: k[0], self.wvecs.most_similar(target, topn = 50)))\n",
    "\n",
    "        # s : lexical substitude (target word's neighbours)\n",
    "        # t : target substitude word\n",
    "        # c : words in sentential context \n",
    "\n",
    "        for s in neighbours:\n",
    "            cos_s_t = self.wvecs.similarity(s, target)\n",
    "            cos_s_c = 0\n",
    "            for c in sentential_context:\n",
    "                if c in self.wvecs:\n",
    "                    cos_s_c += self.wvecs.similarity(s, c)\n",
    "            substitutability[s] = ( cos_s_t + cos_s_c ) / (1 + len(sentential_context))\n",
    "\n",
    "\n",
    "        for i in range(10):\n",
    "            guesses.append(min(substitutability, key=substitutability.get))\n",
    "            del substitutability[min(substitutability, key=substitutability.get)]\n",
    "\n",
    "\n",
    "        return guesses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "According to the baseline, we implemented retrofitting by the formulas which we have in the Retrofitting Word Vectors with Semantic Lexicons section.The norm_word function simply normalize a word in the lexicon. The read_lex function read a lexicon txt file and write it as dictionary for latter use. The write_wvtxt function write the retrofitted new word vector into a new txt file. We tried different α and β values. We set α and β to be 1 at first. We got Score=39. Finally, we let α and β equal to the number of neighbors correspond to a specific word. With the functions for retrofit word vector, we improved the accuracy. We got Score=40.87. Then, we tried to incorporate context words. We attempted to use several formula described in the reference material but it did not work well(the above formula uses Add formula to calculate substitutability). No matter which formula we choose, how many candidates are choosen initial, We got a lower accuracy(lower than 40). From the results wo have got, using retrofit function and default substitutes function gives us a better solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
